horovodrun -np 4 --timeline-filename ./timeline.json --autotune python QA_labeling.py   <- horovod with timeline analysis

average epoch time : 9 minutes

Roberta with multiple heads cannot be serialized

[1,0]<stdout>:epoch 1/20 train loss 0.24157066643238068 test loss 0.21421094238758087 test metric 0.17494607147013644 train metric 0.01710431991231446 epoch time 0:10:47.948148
[1,0]<stdout>:model for RoBERTaForQALabeling saved under ./checkpoints/RoBERTaForQALabeling_fold_0... 
[1,0]<stdout>:epoch 2/20 train loss 0.21758967638015747 test loss 0.20803599059581757 test metric 0.22019492765223206 train metric 0.12856574751719052 epoch time 0:10:23.549445
[1,0]<stdout>:model for RoBERTaForQALabeling saved under ./checkpoints/RoBERTaForQALabeling_fold_0... 
[1,0]<stdout>:epoch 3/20 train loss 0.21130578219890594 test loss 0.2177293598651886 test metric 0.2452044948178507 train metric 0.16808476293073812 epoch time 0:10:23.847785
[1,0]<stdout>:model for RoBERTaForQALabeling saved under ./checkpoints/RoBERTaForQALabeling_fold_0... 
[1,0]<stdout>:epoch 4/20 train loss 0.20473793148994446 test loss 0.20591822266578674 test metric 0.26250929345988766 train metric 0.22432019522639216 epoch time 0:10:22.683130
[1,0]<stdout>:model for RoBERTaForQALabeling saved under ./checkpoints/RoBERTaForQALabeling_fold_0... 
[1,0]<stdout>:epoch 5/20 train loss 0.19648627936840057 test loss 0.20938530564308167 test metric 0.2728415959794089 train metric 0.27644790498687494 epoch time 0:10:25.499834
[1,0]<stdout>:model for RoBERTaForQALabeling saved under ./checkpoints/RoBERTaForQALabeling_fold_0... 
[1,0]<stdout>:epoch 6/20 train loss 0.18933208286762238 test loss 0.20794497430324554 test metric 0.2769724405974012 train metric 0.32127286359028645 epoch time 0:10:22.118229
[1,0]<stdout>:model for RoBERTaForQALabeling saved under ./checkpoints/RoBERTaForQALabeling_fold_0... 
[1,0]<stdout>:epoch 7/20 train loss 0.1832040697336197 test loss 0.208976611495018 test metric 0.27698187258042684 train metric 0.35506321068822405 epoch time 0:10:23.739460
[1,0]<stdout>:model for RoBERTaForQALabeling saved under ./checkpoints/RoBERTaForQALabeling_fold_0... 
[1,0]<stdout>:epoch 8/20 train loss 0.17699848115444183 test loss 0.21284501254558563 test metric 0.2776265276256492 train metric 0.3851405494378835 epoch time 0:10:19.981990
[1,0]<stdout>:model for RoBERTaForQALabeling saved under ./checkpoints/RoBERTaForQALabeling_fold_0... 
[1,0]<stdout>:epoch 9/20 train loss 0.17256446182727814 test loss 0.21056893467903137 test metric 0.2749701936840957 train metric 0.4071048702040331 epoch time 0:10:24.660390
[1,0]<stdout>:epoch 10/20 train loss 0.16833315789699554 test loss 0.20949645340442657 test metric 0.2873057159248978 train metric 0.4307347486141211 epoch time 0:10:44.996591
[1,0]<stdout>:model for RoBERTaForQALabeling saved under ./checkpoints/RoBERTaForQALabeling_fold_0... 
[1,0]<stdout>:epoch 11/20 train loss 0.16472069919109344 test loss 0.21191056072711945 test metric 0.28292583116352676 train metric 0.4514204116308744 epoch time 0:10:51.339517
[1,0]<stdout>:epoch 12/20 train loss 0.1618313193321228 test loss 0.21173332631587982 test metric 0.2928148490119381 train metric 0.46960144390408537 epoch time 0:10:38.125505
[1,0]<stdout>:model for RoBERTaForQALabeling saved under ./checkpoints/RoBERTaForQALabeling_fold_0... 
